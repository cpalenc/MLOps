{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "# from airflow import DAG\n",
    "# from airflow.operators.python_operator import PythonOperator\n",
    "# from airflow.operators.dummy_operator import DummyOperator\n",
    "\n",
    "le = LabelEncoder()\n",
    "isolation_forest = IsolationForest(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir los argumentos del DAG\n",
    "default_args = {\n",
    "    'owner': 'Oscar C',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': False,\n",
    "    'email': ['oecorrechag@gmail.com'],\n",
    "    'retries': 1,\n",
    "    'start_date': datetime(2024, 5, 20),\n",
    "    'retry_delay': timedelta(minutes=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_table(table_name):\n",
    "    # Conexión a MySQL (en docker)\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    # engine = create_engine('mysql+pymysql://root:airflow@127.0.0.1:3306/db')\n",
    "    metadata = MetaData()\n",
    "    mi_tabla = Table(table_name, metadata)\n",
    "    mi_tabla.drop(engine)\n",
    "    ## otra forma de eliminar\n",
    "    # metadata.drop_all(engine, tables=[mi_tabla])\n",
    "\n",
    "# drop_table('raw_data')\n",
    "# drop_table('test_data')\n",
    "# drop_table('penguin_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def raw_data():\n",
    "\n",
    "    # Conexión a MySQL (en docker)\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    # engine = create_engine('mysql+pymysql://root:airflow@127.0.0.1:3306/db')\n",
    "\n",
    "\n",
    "    # load data\n",
    "    # df = pd.read_csv('data/realtor-data.csv', sep = ',', decimal = '.', header = 0, encoding = 'utf-8')\n",
    "    df = pd.read_parquet('data/df_g1_b0.parquet.gzip')\n",
    "    df.columns = ['brokered_by','status','price','bed','bath','acre_lot','street','city','state',\n",
    "                  'zip_code','house_size','prev_sold_date']\n",
    "    print(df.shape)\n",
    "\n",
    "    # Guardar los datos en MySQL\n",
    "    df.to_sql('raw_data', con=engine, if_exists='append', index=False)\n",
    "\n",
    "    \n",
    "    print(\"Datos raw_data guardados en MySQL\") \n",
    "\n",
    "    return df.head()\n",
    "\n",
    "raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data():\n",
    "    # Conexión a la base de datos MySQL\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    # engine = create_engine('mysql+pymysql://root:airflow@127.0.0.1:3306/db')\n",
    "    # Consulta para cargar los datos desde la tabla en la base de datos\n",
    "    query = \"SELECT * FROM raw_data\"\n",
    "    # Leer los datos desde MySQL\n",
    "    df = pd.read_sql(query, con=engine)\n",
    "\n",
    "\n",
    "    # Selecciono como prueba solo las variables numericas\n",
    "    df = df.loc[:,['price','bed','bath','acre_lot','state','house_size','prev_sold_date']]\n",
    "    # Eliminar los registros con faltantes\n",
    "    df = df.dropna()\n",
    "    # limpieza\n",
    "\n",
    "    df[\"año\"] = pd.to_datetime(df['prev_sold_date']).dt.year\n",
    "    df[\"decada\"] = (df[\"año\"] // 10) * 10\n",
    "\n",
    "\n",
    "    df = df[df['bed'] < 7]\n",
    "    df = df[df['bath'] < 5]\n",
    "    df = df[df['price'] < 300000]\n",
    "    df = df[df['acre_lot'] <= 0.0894211]\n",
    "    df = df[df['house_size'] < 3500]\n",
    "    df = df[df['decada'] >= 1980]\n",
    "\n",
    "    encoded_labels = le.fit_transform(df['state'])\n",
    "    df['states'] = encoded_labels\n",
    "\n",
    "    isolation_forest.fit(df.loc[:,['price', 'bed', 'bath', 'acre_lot', 'states', 'house_size']])\n",
    "    anomalies = isolation_forest.predict(df.loc[:,['price', 'bed', 'bath', 'acre_lot', 'states', 'house_size']])\n",
    "    df = df[anomalies == 1]\n",
    "    \n",
    "    df = df.loc[:,['price','bed','bath','acre_lot','states','house_size']]\n",
    "\n",
    "    # Guardar los datos en MySQL\n",
    "    df.to_sql('clean_data', con=engine, if_exists='append', index=False)\n",
    "\n",
    "    print(\"Datos limpios guardados en MySQL\") \n",
    "\n",
    "    return df.head()\n",
    "\n",
    "clean_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos limpios cargados desde MySQL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      bed  bath  acre_lot  states  house_size prev_sold_date\n",
       " 3759  3.0   3.0      0.04      24      1607.0     2005-12-16\n",
       " 414   3.0   2.0      0.03      37      1900.0     2021-02-24\n",
       " 505   2.0   3.0      0.06      31      1764.0     2002-07-09\n",
       " 296   3.0   3.0      0.04      37      1520.0     2019-05-09\n",
       " 1261  3.0   1.0      0.06      37      1534.0     2004-07-30\n",
       " ...   ...   ...       ...     ...         ...            ...\n",
       " 3444  3.0   3.0      0.05      13      1653.0     2007-07-06\n",
       " 466   3.0   2.0      0.08      29      1758.0     1990-02-20\n",
       " 3092  3.0   3.0      0.06      13      1732.0     2019-12-17\n",
       " 3772  3.0   3.0      0.05      24      1865.0     2009-11-02\n",
       " 860   3.0   2.0      0.07      37      1810.0     2021-06-11\n",
       " \n",
       " [4036 rows x 6 columns],\n",
       "       bed  bath  acre_lot  states  house_size prev_sold_date\n",
       " 2269  3.0   3.0      0.04       9      1564.0     2007-07-05\n",
       " 1192  3.0   2.0      0.06      20      1790.0     2017-03-31\n",
       " 2623  3.0   2.0      0.07      17      1717.0     2009-02-09\n",
       " 3048  3.0   2.0      0.07      26      1728.0     2021-09-07\n",
       " 120   5.0   2.0      0.04      29      1694.0     2021-04-17\n",
       " ...   ...   ...       ...     ...         ...            ...\n",
       " 1412  3.0   2.0      0.05      37      1606.0     1994-11-18\n",
       " 1556  3.0   2.0      0.07      37      1521.0     2010-08-10\n",
       " 1907  3.0   3.0      0.04      45      1512.0     2013-12-16\n",
       " 3176  2.0   2.0      0.06      22      1502.0     2008-08-11\n",
       " 1592  3.0   2.0      0.04      20      1580.0     2008-03-26\n",
       " \n",
       " [213 rows x 6 columns],\n",
       " 3759    200000.0\n",
       " 414     219900.0\n",
       " 505     175000.0\n",
       " 296     200000.0\n",
       " 1261     95000.0\n",
       "           ...   \n",
       " 3444    245000.0\n",
       " 466     265000.0\n",
       " 3092    232000.0\n",
       " 3772    249950.0\n",
       " 860     205000.0\n",
       " Name: price, Length: 4036, dtype: float64,\n",
       " 2269    182900.0\n",
       " 1192    255000.0\n",
       " 2623    160000.0\n",
       " 3048    172500.0\n",
       " 120     199900.0\n",
       "           ...   \n",
       " 1412    199900.0\n",
       " 1556    174900.0\n",
       " 1907    285000.0\n",
       " 3176    285000.0\n",
       " 1592    285000.0\n",
       " Name: price, Length: 213, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_slip():\n",
    "    # Conexión a la base de datos MySQL\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    # engine = create_engine('mysql+pymysql://root:airflow@127.0.0.1:3306/db')\n",
    "    # Consulta para cargar los datos desde la tabla en la base de datos\n",
    "    query = \"SELECT * FROM clean_data\"\n",
    "    # Leer los datos desde MySQL\n",
    "    df = pd.read_sql(query, con=engine)\n",
    "    # Convertir las columnas 'Sex' y 'Species' a tipo categórico\n",
    "    # df[['Wilderness_Area', 'Soil_Type','Cover_Type']] = df[['Wilderness_Area', 'Soil_Type','Cover_Type']].astype('category')\n",
    "    # Dividir los datos en características (X) y etiquetas (y)\n",
    "    X = df.drop(columns='price')\n",
    "    y = df['price']\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42) \n",
    "    \n",
    "    print(\"Datos limpios cargados desde MySQL\")  \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "load_and_slip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# xgb_pipeline -> data\n",
    "X_train, X_test, y_train, y_test = load_and_slip()\n",
    "\n",
    "param_dist = {\n",
    "    'xgb__n_estimators': randint(50, 200),\n",
    "    'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.3),\n",
    "    'xgb__subsample': uniform(0.7, 0.3),\n",
    "    'xgb__colsample_bytree': uniform(0.7, 0.3)\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, \n",
    "                                   param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Ajustar el modelo\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo después de la búsqueda\n",
    "best_model = random_search.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos limpios cargados desde MySQL\n",
      "inicia el experimento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mlflow/types/utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'tracking-house-XGB'.\n",
      "2024/05/30 21:17:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: tracking-house-XGB, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finaliza el experimento\n",
      "Trained successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'tracking-house-XGB'.\n"
     ]
    }
   ],
   "source": [
    "def model_train():\n",
    "\n",
    "\n",
    "    # conectar con mlflow y minio\n",
    "    mlflow.set_tracking_uri(\"http://Mlflow:5000\")\n",
    "\n",
    "    os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://Minio:9000\"\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = load_and_slip()\n",
    "\n",
    "    EXPERIMENT_NAME = \"Classifier-Experiment\"\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    #agregaron para eliminar el resto\n",
    "    mlflow.sklearn.autolog(log_input_examples=True, log_model_signatures=True, registered_model_name='modelo_test')    \n",
    "\n",
    "    current_experiment=dict(mlflow.get_experiment_by_name(EXPERIMENT_NAME))\n",
    "    # experiment_id=current_experiment['experiment_id']\n",
    "\n",
    "    print('inicia el experimento')\n",
    "\n",
    "    model_name = 'XGB'\n",
    "    with mlflow.start_run(run_name=\"tracking-house-XGB\") as run:\n",
    "\n",
    "        model = xgb.XGBRegressor(n_estimators=18)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test) \n",
    "\n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # # Log the hyperparameters\n",
    "        # mlflow.log_params(params)\n",
    "\n",
    "        # Log the loss metric\n",
    "        mlflow.log_metric(f\"{model_name}_r2\", r2)\n",
    "        mlflow.log_metric(f\"{model_name}_mae\", mae)\n",
    "        mlflow.log_metric(f\"{model_name}_mse\", mse)\n",
    "        mlflow.log_metric(f\"{model_name}_rmse\", rmse)\n",
    "\n",
    "        model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "        model_details = mlflow.register_model(model_uri=model_uri, name=\"cover_type_class\")\n",
    "\n",
    "        # Set a tag that we can use to remind ourselves what this run was for\n",
    "        mlflow.set_tag(\"Training Info\", f\"{model_name} model for regression\")\n",
    "\n",
    "        # Infer the model signature\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "        # og the model\n",
    "\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=f\"house_{model_name}_model\",\n",
    "            # signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"tracking-house-{model_name}\"\n",
    "        )\n",
    "\n",
    "        print('finaliza el experimento')\n",
    "\n",
    "        mlflow.end_run() \n",
    "\n",
    "    client = MlflowClient()\n",
    "    client.set_registered_model_tag(\"tracking-house-XGB\", \"task\", \"regression\")\n",
    "\n",
    "    print(\"Trained\")\n",
    "\n",
    "model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194975.64], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predic_model_train(data_predict):\n",
    "\n",
    "\n",
    "    # conectar con mlflow y minio\n",
    "    mlflow.set_tracking_uri(\"http://Mlflow:5000\")\n",
    "\n",
    "    os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://Minio:9000\"\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "\n",
    "    model_name = \"tracking-house-XGB\"\n",
    "    model_version = 1\n",
    "\n",
    "    lr = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "    return lr.predict(data_predict)\n",
    "\n",
    "\n",
    "user_input = [3.0, 2.0, 0.09, 302, 1409.0]\n",
    "columns = ['bed','bath','acre_lot', 'states', 'house_size']\n",
    "df_pred = pd.DataFrame([user_input], columns=columns)\n",
    "out_model = predic_model_train(df_pred)\n",
    "out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('ok_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
