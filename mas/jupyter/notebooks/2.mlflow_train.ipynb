{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "# from airflow import DAG\n",
    "# from airflow.operators.python_operator import PythonOperator\n",
    "# from airflow.operators.dummy_operator import DummyOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir los argumentos del DAG\n",
    "default_args = {\n",
    "    'owner': 'Oscar C',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': False,\n",
    "    'email': ['oecorrechag@gmail.com'],\n",
    "    'retries': 1,\n",
    "    'start_date': datetime(2024, 5, 20),\n",
    "    'retry_delay': timedelta(minutes=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_table(table_name):\n",
    "    # Conexión a MySQL (en docker)\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    metadata = MetaData()\n",
    "    mi_tabla = Table(table_name, metadata)\n",
    "    mi_tabla.drop(engine)\n",
    "    ## otra forma de eliminar\n",
    "    # metadata.drop_all(engine, tables=[mi_tabla])\n",
    "\n",
    "# drop_table('iris_table')\n",
    "# drop_table('raw')\n",
    "# drop_table('clean_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop_table('penguin_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def raw_data():\n",
    "\n",
    "    # Conexión a MySQL (en docker)\n",
    "    # engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@127.0.0.1:3306/db')\n",
    "\n",
    "\n",
    "    # load data\n",
    "    df = pd.read_csv('data/realtor-data.csv', sep = ',', decimal = '.', header = 0, encoding = 'utf-8')\n",
    "    df.columns = ['brokered_by','status','price','bed','bath','acre_lot','street','city','state',\n",
    "                  'zip_code','house_size','prev_sold_date']\n",
    "    # tomar el 10% para que guarde\n",
    "    df = df.sample(frac=0.1, random_state=42)\n",
    "    print(df.shape)\n",
    "\n",
    "    # Guardar los datos en MySQL\n",
    "    df.to_sql('raw_data', con=engine, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "    print(\"Datos raw_data guardados en MySQL\") \n",
    "\n",
    "    return df.head()\n",
    "\n",
    "raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data():\n",
    "    # Conexión a la base de datos MySQL\n",
    "    # engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@127.0.0.1:3306/db')\n",
    "    # Consulta para cargar los datos desde la tabla en la base de datos\n",
    "    query = \"SELECT * FROM raw_data\"\n",
    "    # Leer los datos desde MySQL\n",
    "    df = pd.read_sql(query, con=engine)\n",
    "\n",
    "\n",
    "    # Selecciono como prueba solo las variables numericas\n",
    "    df = df.loc[:,['price','bed','bath','acre_lot','street','house_size']]\n",
    "    # Eliminar los registros con faltantes\n",
    "    df = df.dropna()\n",
    "    # Convertir en string el zip code\n",
    "    df['zip_code'] = df['zip_code'].astype(str)\n",
    "    # print(df.shape)\n",
    "    \n",
    "\n",
    "    # Guardar los datos en MySQL\n",
    "    df.to_sql('clean_data', con=engine, if_exists='append', index=False)\n",
    "\n",
    "    print(\"Datos limpios guardados en MySQL\") \n",
    "\n",
    "    return df.head()\n",
    "\n",
    "clean_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_slip():\n",
    "    # Conexión a la base de datos MySQL\n",
    "    engine = create_engine('mysql+pymysql://root:airflow@mysql:3306/db')\n",
    "    # Consulta para cargar los datos desde la tabla en la base de datos\n",
    "    query = \"SELECT * FROM clean_data\"\n",
    "    # Leer los datos desde MySQL\n",
    "    df = pd.read_sql(query, con=engine)\n",
    "    # Convertir las columnas 'Sex' y 'Species' a tipo categórico\n",
    "    # df[['Wilderness_Area', 'Soil_Type','Cover_Type']] = df[['Wilderness_Area', 'Soil_Type','Cover_Type']].astype('category')\n",
    "    # Dividir los datos en características (X) y etiquetas (y)\n",
    "    X = df.drop(columns='price')\n",
    "    y = df['price']\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "    \n",
    "    print(\"Datos limpios cargados desde MySQL\")  \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "load_and_slip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_train():\n",
    "\n",
    "\n",
    "    # conectar con mlflow y minio\n",
    "    mlflow.set_tracking_uri(\"http://Mlflow:5000\")\n",
    "\n",
    "    os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://Minio:9000\"\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = load_and_slip()\n",
    "\n",
    "    EXPERIMENT_NAME = \"Classifier-Experiment\"\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    current_experiment=dict(mlflow.get_experiment_by_name(EXPERIMENT_NAME))\n",
    "    experiment_id=current_experiment['experiment_id']\n",
    "\n",
    "    print('inicia el experimento')\n",
    "\n",
    "    model_name = 'Lineal model'\n",
    "    RUN_NAME = f'Regression Experiment {model_name}'\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=RUN_NAME):\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test) \n",
    "\n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Log the hyperparameters\n",
    "        mlflow.log_params()\n",
    "\n",
    "        # Log the loss metric\n",
    "        mlflow.log_metric(f\"{model_name}_mse\", mse)\n",
    "        mlflow.log_metric(f\"{model_name}_rmse\", rmse)\n",
    "        mlflow.log_metric(f\"{model_name}_mae\", mae)\n",
    "        mlflow.log_metric(f\"{model_name}_r2\", r2)\n",
    "\n",
    "        # Set a tag that we can use to remind ourselves what this run was for\n",
    "        mlflow.set_tag(\"Training Info\", f\"{model_name} model for regression\")\n",
    "\n",
    "        # Infer the model signature\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "        \n",
    "        #log the model\n",
    "\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=f\"house_{model_name}_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"tracking-house-{model_name}\"\n",
    "        )\n",
    "\n",
    "        print('finaliza el experimento')\n",
    "\n",
    "        mlflow.end_run() \n",
    "\n",
    "    client = MlflowClient()\n",
    "    client.set_registered_model_tag(\"tracking-house-Lineal model\", \"task\", \"regression\")\n",
    "\n",
    "    print(\"Trained successfully.\")\n",
    "\n",
    "model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predic_model_train(data_predict):\n",
    "\n",
    "\n",
    "    # conectar con mlflow y minio\n",
    "    mlflow.set_tracking_uri(\"http://Mlflow:5000\")\n",
    "\n",
    "    os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://Minio:9000\"\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "\n",
    "    model_name = \"tracking-house-Lineal model\"\n",
    "    model_version = 1\n",
    "\n",
    "    lr = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "    return lr.predict(data_predict)\n",
    "\n",
    "\n",
    "user_input = [3, 2, 0.09, 892999.0, 1409.0]\n",
    "columns = ['bed','bath','acre_lot','street','house_size']\n",
    "df_pred = pd.DataFrame([user_input], columns=columns)\n",
    "out_model = predic_model_train(df_pred[0])\n",
    "out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('ok_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
